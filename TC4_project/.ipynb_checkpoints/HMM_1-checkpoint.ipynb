{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> This file, using python3.6, realized one order HMM with forward-backward and viterbi algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#address of dossier\n",
    "adr_test10 = './data/test10.pkl'\n",
    "adr_train10 = './data/train10.pkl'\n",
    "adr_test20 = './data/test20.pkl'\n",
    "adr_train20 = './data/train20.pkl'\n",
    "\n",
    "\n",
    "#read in the data\n",
    "test10 = pickle.load(open(adr_test10, \"rb\"))\n",
    "train10 = pickle.load(open(adr_train10, \"rb\"))\n",
    "test20 = pickle.load(open(adr_test20, \"rb\"))\n",
    "train20 = pickle.load(open(adr_train20, \"rb\"))\n",
    "voc_tag = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Compute HMM parameter: A, B, Pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcule_parametres(mydata):\n",
    "    # the list of all hidden states\n",
    "    states = []\n",
    "    for i in range(len(mydata)):\n",
    "        for j in range(len(mydata[i])):\n",
    "            states.append(mydata[i][j][1])\n",
    "    states = list(set(states))\n",
    "    # print(states)\n",
    "\n",
    "    # the list of all observations\n",
    "    observations = []\n",
    "    for i in range(len(mydata)): \n",
    "        for j in range(len(mydata[i])):\n",
    "            observations.append(mydata[i][j][0])\n",
    "    observations = list(set(observations))\n",
    "    # print(observations)\n",
    "\n",
    "    # compute the first state prob\n",
    "    pi = {}\n",
    "    for index in states:\n",
    "        pi[index] = 0\n",
    "    for i in range(len(mydata)):\n",
    "        pi[mydata[i][0][1]] += 1\n",
    "    for index in states:\n",
    "        pi[index] /= float(len(mydata))\n",
    "    pi = Series(pi)\n",
    "    # print(pi)\n",
    "\n",
    "    # compute the transition prob\n",
    "    A = DataFrame(np.zeros([len(states),len(states)]),columns=states, index=states)\n",
    "    for i in range(len(mydata)):\n",
    "        for j in range(len(mydata[i])-1):\n",
    "            A[mydata[i][j][1]][mydata[i][j+1][1]] += 1\n",
    "    for index in states:\n",
    "        A[index] /= float(sum(A[index]))\n",
    "    # print(A)\n",
    "\n",
    "    # compute the emission prob \n",
    "    B = DataFrame(np.zeros([len(observations),len(states)]),columns=states, index=observations)\n",
    "    for i in range(len(mydata)):\n",
    "        for j in range(len(mydata[i])):\n",
    "            B[mydata[i][j][1]][mydata[i][j][0]] += 1\n",
    "    for index in states:\n",
    "        B[index] /= float(sum(B[index]))\n",
    "    # print(B)\n",
    "    \n",
    "    return pi, A, B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> The implementation of forward-backward algrithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to calculate parameters alpha\n",
    "def forward_parameter(pi,A,B,word):\n",
    "    alpha = DataFrame(np.zeros([len(voc_tag),len(word)]),columns=range(len(word)), index=voc_tag)\n",
    "    #initialization of first column\n",
    "    alpha.loc[:,0] = pi*B.iloc[list(B.index).index(word[0][0])]\n",
    "    if len(word) == 1:\n",
    "        return alpha\n",
    "    else:\n",
    "        for i in range(len(word)-1):\n",
    "            alpha.loc[:,i+1] = B.iloc[list(B.index).index(word[i+1][0])]*((A*alpha.loc[:,i]).sum(axis=1))\n",
    "        return alpha\n",
    "\n",
    "# function to calculate parameters beta\n",
    "def backward_parameter(pi,A,B,word):\n",
    "    beta = DataFrame(np.zeros([len(voc_tag),len(word)]),columns=range(len(word)), index=voc_tag)\n",
    "    #initialization of first column\n",
    "    beta.loc[:,len(word)-1] = np.ones(len(voc_tag))\n",
    "    if len(word) == 1:\n",
    "        return beta\n",
    "    else:\n",
    "        for i in range(len(word)-1):\n",
    "            beta.loc[:,len(word)-2-i] = (beta.loc[:,len(word)-1-i]*B.iloc[list(B.index).index(word[len(word)-1-i][0])]).dot(A)\n",
    "        return beta\n",
    "    \n",
    "# compute the ideal word using forawrd-backward\n",
    "def FB(pi,A,B,word):\n",
    "    alpha = forward_parameter(pi,A,B,word)\n",
    "    beta = backward_parameter(pi,A,B,word)\n",
    "    joint_prob = alpha * beta\n",
    "    return joint_prob.idxmax(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> The implementation of viterbi algrithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute the ideal word using viterbi\n",
    "def VITERBI(pi,A,B,word):\n",
    "    result = []\n",
    "    mu = DataFrame(np.zeros([len(voc_tag),len(word)]),columns=range(len(word)), index=voc_tag)\n",
    "    idx = DataFrame(np.zeros([len(voc_tag),len(word)-1]),columns=range(len(word)-1), index=voc_tag)\n",
    "    #initialization of first column\n",
    "    mu.loc[:,0] = pi*B.iloc[list(B.index).index(word[0][0])]\n",
    "    if len(word) == 1:\n",
    "        return mu.idxmax(axis=0)\n",
    "    else:\n",
    "        for i in range(len(word)-1):\n",
    "            temp = A*mu.loc[:,i]\n",
    "            idx.loc[:,i] = temp.idxmax(axis=1)\n",
    "            mu.loc[:,i+1] = B.iloc[list(B.index).index(word[i+1][0])]*temp.max(axis=1)\n",
    "        result.append((mu.loc[:,len(word)-1]).idxmax(axis=0))\n",
    "        for i in range(len(word)-1):\n",
    "            result.insert(0,idx.loc[result[0],len(word)-2-i]) \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test function for certain trainset and testset.\n",
    "# return baseline, fb_result, viterbi_result.\n",
    "# for each result, as a list [error_rate, num_error_corrected, num_error_created, true_positive, false_negative]\n",
    "def test_part(train,test):\n",
    "    #caculate parameters of HMM according to train data\n",
    "    pi,A,B = calcule_parametres(train)\n",
    "    right_positive_fb = 0.0\n",
    "    right_positive_viterbi = 0.0\n",
    "    positive = 0.0\n",
    "    wrong_negative_fb = 0.0\n",
    "    wrong_negative_viterbi = 0.0\n",
    "    negative = 0.0\n",
    "    #test the performance for test set\n",
    "    for word in test:\n",
    "        corrected_word_fb = FB(pi,A,B,word)\n",
    "        corrected_word_viterbi = VITERBI(pi,A,B,word)\n",
    "        for i in range(len(word)):\n",
    "            if word[i][0] == word[i][1]:\n",
    "                positive += 1\n",
    "                if corrected_word_fb[i] == word[i][1]:\n",
    "                    right_positive_fb += 1\n",
    "                if corrected_word_viterbi[i] == word[i][1]:\n",
    "                    right_positive_viterbi += 1\n",
    "            else:\n",
    "                negative += 1\n",
    "                if not corrected_word_fb[i] == word[i][1]:\n",
    "                    wrong_negative_fb += 1\n",
    "                if not corrected_word_viterbi[i] == word[i][1]:\n",
    "                    wrong_negative_viterbi += 1\n",
    "    \n",
    "    # compute several evaluation critics\n",
    "    total = positive + negative\n",
    "    baseline = negative / total\n",
    "    \n",
    "    fb = []\n",
    "    error_rate = (positive - right_positive_fb + wrong_negative_fb) / total\n",
    "    fb.append(error_rate)\n",
    "    \n",
    "    num_error_corrected = negative - wrong_negative_fb\n",
    "    fb.append(num_error_corrected)\n",
    "    \n",
    "    num_error_created = positive - right_positive_fb\n",
    "    fb.append(num_error_created)\n",
    "    \n",
    "    right_positive_fb /= positive\n",
    "    fb.append(right_positive_fb)\n",
    "    \n",
    "    wrong_negative_fb /= negative\n",
    "    fb.append(wrong_negative_fb)\n",
    "    \n",
    "    viterbi = []\n",
    "    error_rate = (positive - right_positive_viterbi + wrong_negative_viterbi) / total\n",
    "    viterbi.append(error_rate)\n",
    "    \n",
    "    num_error_corrected = negative - wrong_negative_viterbi\n",
    "    viterbi.append(num_error_corrected)\n",
    "    \n",
    "    num_error_created = positive - right_positive_viterbi\n",
    "    viterbi.append(num_error_created)\n",
    "    \n",
    "    right_positive_viterbi /= positive\n",
    "    viterbi.append(right_positive_viterbi)\n",
    "    wrong_negative_viterbi /= negative\n",
    "    viterbi.append(wrong_negative_viterbi)\n",
    "    \n",
    "    return baseline, fb, viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>The results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the result of data-set with 10% error:\n",
      "------------------------------------------------------\n",
      "The baseline is: 0.10177595628415301\n",
      "------------------------------------------------------\n",
      "The error-rate using fb is: 0.06762295081967214\n",
      "The number of corrected error using fb is: 304.0\n",
      "The number of created error using fb is: 54.0\n",
      "The true positive rate using fb is: 0.9917870722433461\n",
      "The false negative rate using fb is: 0.5919463087248322\n",
      "------------------------------------------------------\n",
      "The error-rate using viterbi is: 0.0680327868852459\n",
      "The number of corrected error using viterbi is: 310.0\n",
      "The number of created error using viterbi is: 63.0\n",
      "The true positive rate using viterbi is: 0.9904182509505703\n",
      "The false negative rate using viterbi is: 0.5838926174496645\n"
     ]
    }
   ],
   "source": [
    "baseline, fb, viterbi = test_part(train10, test10)\n",
    "print(\"Here are the result of data-set with 10% error:\")\n",
    "print(\"------------------------------------------------------\")\n",
    "print(\"The baseline is: \" + str(baseline))\n",
    "print(\"------------------------------------------------------\")\n",
    "print(\"The error-rate using fb is: \" + str(fb[0]))\n",
    "print(\"The number of corrected error using fb is: \" + str(fb[1]))\n",
    "print(\"The number of created error using fb is: \" + str(fb[2]))\n",
    "print(\"The true positive rate using fb is: \" + str(fb[3]))\n",
    "print(\"The false negative rate using fb is: \" + str(fb[4]))\n",
    "print(\"------------------------------------------------------\")\n",
    "print(\"The error-rate using viterbi is: \" + str(viterbi[0]))\n",
    "print(\"The number of corrected error using viterbi is: \" + str(viterbi[1]))\n",
    "print(\"The number of created error using viterbi is: \" + str(viterbi[2]))\n",
    "print(\"The true positive rate using viterbi is: \" + str(viterbi[3]))\n",
    "print(\"The false negative rate using viterbi is: \" + str(viterbi[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the result of data-set with 20% error:\n",
      "------------------------------------------------------\n",
      "The baseline is: 0.19405667725121323\n",
      "------------------------------------------------------\n",
      "The error-rate using fb is: 0.13132826073932058\n",
      "The number of corrected error using fb is: 1309.0\n",
      "The number of created error using fb is: 262.0\n",
      "The true positive rate using fb is: 0.9805233422539399\n",
      "The false negative rate using fb is: 0.595862920654523\n",
      "------------------------------------------------------\n",
      "The error-rate using viterbi is: 0.13132826073932058\n",
      "The number of corrected error using viterbi is: 1366.0\n",
      "The number of created error using viterbi is: 319.0\n",
      "The true positive rate using viterbi is: 0.9762860541183467\n",
      "The false negative rate using viterbi is: 0.5782648965730164\n"
     ]
    }
   ],
   "source": [
    "baseline, fb, viterbi = test_part(train20, test20)\n",
    "print(\"Here are the result of data-set with 20% error:\")\n",
    "print(\"------------------------------------------------------\")\n",
    "print(\"The baseline is: \" + str(baseline))\n",
    "print(\"------------------------------------------------------\")\n",
    "print(\"The error-rate using fb is: \" + str(fb[0]))\n",
    "print(\"The number of corrected error using fb is: \" + str(fb[1]))\n",
    "print(\"The number of created error using fb is: \" + str(fb[2]))\n",
    "print(\"The true positive rate using fb is: \" + str(fb[3]))\n",
    "print(\"The false negative rate using fb is: \" + str(fb[4]))\n",
    "print(\"------------------------------------------------------\")\n",
    "print(\"The error-rate using viterbi is: \" + str(viterbi[0]))\n",
    "print(\"The number of corrected error using viterbi is: \" + str(viterbi[1]))\n",
    "print(\"The number of created error using viterbi is: \" + str(viterbi[2]))\n",
    "print(\"The true positive rate using viterbi is: \" + str(viterbi[3]))\n",
    "print(\"The false negative rate using viterbi is: \" + str(viterbi[4]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> This file, using python3.6, realized one order HMM with forward-backward and viterbi algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#address of dossier\n",
    "adr_test10 = './data/test10.pkl'\n",
    "adr_train10 = './data/train10.pkl'\n",
    "adr_test20 = './data/test20.pkl'\n",
    "adr_train20 = './data/train20.pkl'\n",
    "\n",
    "\n",
    "#read in the data\n",
    "test10 = pickle.load(open(adr_test10, \"rb\"))\n",
    "train10 = pickle.load(open(adr_train10, \"rb\"))\n",
    "test20 = pickle.load(open(adr_test20, \"rb\"))\n",
    "train20 = pickle.load(open(adr_train20, \"rb\"))\n",
    "voc_tag = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Compute HMM parameter: A, B, Pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcule_Parametres(mydata):\n",
    "    #list de tag\n",
    "    state_list = []\n",
    "    for i in range(len(mydata)):\n",
    "        for j in range(len(mydata[i])):\n",
    "            state_list.append(mydata[i][j][1])\n",
    "    state_list = list(set(state_list))\n",
    "    #vocabulaire\n",
    "    vocabulaire = []\n",
    "    for i in range(len(mydata)): \n",
    "        for j in range(len(mydata[i])):\n",
    "            vocabulaire.append(mydata[i][j][0])\n",
    "    \n",
    "    vocabulaire = list(set(vocabulaire))\n",
    "    \n",
    "    #calculate parameters N1,N2,N3,C0,C1,C2,NW2,NW3\n",
    "    N1C1 = Series(np.zeros(len(state_list)),index=state_list)\n",
    "    N2C2 = DataFrame(np.zeros([len(state_list),len(state_list)]),columns=state_list, index=state_list)\n",
    "    N3 = DataFrame(columns=state_list, index=range(1))\n",
    "    for index in state_list:\n",
    "        N3[index][0] = DataFrame(np.zeros([len(state_list),len(state_list)]),columns=state_list, index=state_list)\n",
    "    C0 = 0\n",
    "    NW = Series(np.zeros(len(vocabulaire)),index=state_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "    NW3 = DataFrame(columns=vocabulaire, index=range(1))\n",
    "    for voc in vocabulaire:\n",
    "        NW3[voc][0] = DataFrame(np.zeros([len(state_list),len(state_list)]),columns=state_list, index=state_list)\n",
    "    \n",
    "    #calcule the distribution for pi\n",
    "    distribution_de_tag_initial = {}\n",
    "    for index in state_list:\n",
    "        distribution_de_tag_initial[index] = 0\n",
    "    for i in range(len(mydata)):\n",
    "        distribution_de_tag_initial[mydata[i][0][1]] += 1\n",
    "    for index in state_list:\n",
    "        distribution_de_tag_initial[index] /= float(len(mydata))\n",
    "    pi = Series(distribution_de_tag_initial)\n",
    "     \n",
    "    #calcule the matrix B_1\n",
    "    B_1 = DataFrame(np.zeros([len(vocabulaire),len(state_list)]),columns=state_list, index=vocabulaire)\n",
    "    for i in range(len(mydata)):\n",
    "        for j in range(len(mydata[i])):\n",
    "            B_1[mydata[i][j][1]][mydata[i][j][0]] += 1\n",
    "    NW2 = B_1.copy(deep=True)\n",
    "    for index in state_list:\n",
    "        B_1[index] /= float(sum(B_1[index]))\n",
    "    \n",
    "    for i in range(len(mydata)):\n",
    "        for j in range(len(mydata[i])):\n",
    "            N1C1[mydata[i][j][1]] += 1\n",
    "            NW[mydata[i][j][0]] += 1\n",
    "            C0 += 1\n",
    "            if len(mydata[i])-j == 1: continue\n",
    "            \n",
    "            N2C2[mydata[i][j][1]][mydata[i][j+1][1]] += 1\n",
    "            NW3[mydata[i][j+1][0]][0][mydata[i][j][1]][mydata[i][j+1][1]] += 1    \n",
    "                \n",
    "            if len(mydata[i])-j-1 == 1: continue\n",
    "            N3[mydata[i][j][1]][0][mydata[i][j+1][1]][mydata[i][j+2][1]] += 1\n",
    "    \n",
    "    #calculate a_ij\n",
    "    A_1 = DataFrame(np.zeros([len(state_list),len(state_list)]),columns=state_list, index=state_list)\n",
    "    for index_1 in state_list:\n",
    "        for index_2 in state_list:\n",
    "            k2 = (np.log(N2C2[index_1][index_2]+1)+1)/(np.log(N2C2[index_1][index_2]+1)+2)\n",
    "            if N1C1[index_1]==0: temp1=0\n",
    "            else: temp1 = k2*N2C2[index_1][index_2]/N1C1[index_1]\n",
    "            temp2 = (1-k2)*N1C1[index_2]/C0\n",
    "            A_1[index_1][index_2] = temp1 + temp2\n",
    "    \n",
    "    \n",
    "    \n",
    "    #calculate a_ijk\n",
    "    A_ = DataFrame(columns=state_list,index=range(1))\n",
    "    for index in state_list:\n",
    "        A_[index][0] = DataFrame(np.zeros([len(state_list),len(state_list)]), columns=state_list, index=state_list)\n",
    "    for index_1 in state_list:\n",
    "        for index_2 in state_list:\n",
    "            for index_3 in state_list:\n",
    "                k2 = (np.log(N2C2[index_2][index_3]+1)+1)/(np.log(N2C2[index_2][index_3]+1)+2)\n",
    "                k3 = (np.log(N3[index_1][0][index_2][index_3]+1)+1)/(np.log(N3[index_1][0][index_2][index_3]+1)+2)\n",
    "                if N2C2[index_1][index_2] == 0: temp1=0\n",
    "                else:  temp1 = k3*N3[index_1][0][index_2][index_3]/N2C2[index_1][index_2]\n",
    "                if N1C1[index_2]==0: temp2=0\n",
    "                else: temp2 = (1-k3)*k2*N2C2[index_2][index_3]/N1C1[index_2]\n",
    "                temp3 = (1-k2)*(1-k3)*N1C1[index_3]/C0\n",
    "                A_[index_1][0][index_2][index_3] = temp1 + temp2 + temp3\n",
    "    \n",
    "    #calculate bk_ij\n",
    "    \n",
    "    B_ = DataFrame(columns=vocabulaire, index=range(1))\n",
    "    for voc in vocabulaire:\n",
    "        B_[voc][0] = DataFrame(np.zeros([len(state_list),len(state_list)]), columns=state_list, index=state_list)\n",
    "    for index_1 in state_list:\n",
    "        for index_2 in state_list:\n",
    "            for voc in vocabulaire:\n",
    "                k3 = (np.log(NW3[voc][0][index_1][index_2]+1)+1)/(np.log(NW3[voc][0][index_1][index_2]+1)+2)\n",
    "                if N2C2[index_1][index_2] == 0: temp1=0\n",
    "                else: temp1 = k3*NW3[voc][0][index_1][index_2]/N2C2[index_1][index_2]\n",
    "                if N1C1[index_2] == 0: temp2 = 0\n",
    "                else: temp2 = (1-k3)*NW2[index_2][voc]/N1C1[index_2]\n",
    "                B_[voc][0][index_1][index_2] = temp1 + temp2     \n",
    "    \n",
    "    return pi,A_1,B_1,A_,B_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> The implementation of forward-backward algrithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to calculate parameters alpha\n",
    "def forward_parameter(pi,A,B,A_1,B_1,word):\n",
    "    if len(word) == 1:\n",
    "        alpha = DataFrame(np.zeros([len(voc_tag),len(word)]),columns=range(len(word)), index=voc_tag)\n",
    "        #initialization of first column\n",
    "        alpha.loc[:,0] = pi*B_1.iloc[list(B_1.index).index(word[0][0])]\n",
    "        return alpha\n",
    "    alpha = DataFrame(columns=range(len(word)-1), index=range(1))\n",
    "    #initialization\n",
    "    alpha[0][0] = B_1.loc[:,word[0][0]]*B[word[1][0]][0]*A_1*pi\n",
    "    if (len(word)==2):\n",
    "        return alpha\n",
    "    else:\n",
    "        temp=[]\n",
    "        for i in range(len(word)-2):\n",
    "            for index in voc_tag:\n",
    "                temp.append(A[index][0].apply(lambda x: x*(np.array(alpha[i][0][index])),axis=1))\n",
    "            alpha[i+1][0] = B[word[i+2][0]][0]*sum(temp)\n",
    "    return alpha\n",
    "\n",
    "#use original form here\n",
    "#function to calculate parameters beta\n",
    "def backward_parameter(pi,A,B,A_1,B_1,word):\n",
    "    \n",
    "    if len(word) == 1:\n",
    "        beta = DataFrame(np.zeros([len(voc_tag),len(word)]),columns=range(len(word)), index=voc_tag)\n",
    "        #initialization of first column\n",
    "        beta.loc[:,len(word)-1] = np.ones(len(voc_tag))\n",
    "        return beta\n",
    "    beta = DataFrame(columns=range(len(word)-1),index=range(1))\n",
    "    for i in range(len(word)-1):\n",
    "        beta[i][0] = DataFrame(np.zeros([len(voc_tag),len(voc_tag)]), columns=voc_tag, index=voc_tag)\n",
    "    beta[len(word)-2][0] = DataFrame(np.ones([len(voc_tag),len(voc_tag)]), columns=voc_tag, index=voc_tag)\n",
    "    if (len(word)==2):\n",
    "        return beta\n",
    "    else:                \n",
    "        for i in range(len(word)-2):\n",
    "            param = B[word[len(word)-i-1][0]][0]*beta[len(word)-2-i][0]\n",
    "            temp1 = A.loc[0,:].apply(lambda x: x*np.array(param))\n",
    "            temp2 = temp1.apply(lambda x: x.sum(axis=0))\n",
    "            for index in voc_tag:\n",
    "                beta[len(word)-3-i][0].loc[index,:] = temp2[index]\n",
    "        return beta\n",
    "\n",
    "\n",
    "\n",
    "def get_idx(joint_prob):\n",
    "    value = joint_prob.sum(axis=1).idxmax()\n",
    "    return value\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#calculate the best tag for a word(according to algorithm forward-backward,i.e we try to maxmize p(y_i|X) for every y_i)\n",
    "def tag_calculation(pi,A_,B_,A_1,B_1,word):\n",
    "    alpha = forward_parameter(pi,A_,B_,A_1,B_1,word)\n",
    "    beta = backward_parameter(pi,A_,B_,A_1,B_1,word)\n",
    "    temp = []\n",
    "    if len(word)==1:\n",
    "        joint_prob = alpha * beta\n",
    "        return joint_prob.idxmax(axis=0)\n",
    "    for i in range(len(word)-1):\n",
    "        joint_prob = alpha[i][0]*beta[i][0]\n",
    "        if i==0:\n",
    "            temp.append(joint_prob.sum(axis=0).idxmax())\n",
    "        temp.append(get_idx(joint_prob))\n",
    "        \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test function for certain trainset and testset.\n",
    "# return baseline, result.\n",
    "# for each result, as a list [error_rate, num_error_corrected, num_error_created, true_positive, false_negative]\n",
    "def test_part(train,test):\n",
    "    #caculate parameters of HMM according to train data\n",
    "    pi,A_1,B_1,A_,B_ = calcule_Parametres(train)\n",
    "    right_positive = 0.0\n",
    "    positive = 0.0\n",
    "    wrong_negative = 0.0\n",
    "    negative = 0.0\n",
    "    #test the performance for test set\n",
    "    for word in test:\n",
    "        corrected_word = tag_calculation(pi,A_,B_,A_1,B_1,word)\n",
    "        for i in range(len(word)):\n",
    "            if word[i][0] == word[i][1]:\n",
    "                positive += 1\n",
    "                if corrected_word[i] == word[i][1]:\n",
    "                    right_positive += 1\n",
    "            else:\n",
    "                negative += 1\n",
    "                if not corrected_word[i] == word[i][1]:\n",
    "                    wrong_negative += 1\n",
    "\n",
    "    total = positive + negative\n",
    "    baseline = negative / total\n",
    "    \n",
    "    res = []\n",
    "    error_rate = (positive - right_positive + wrong_negative) / total\n",
    "    res.append(error_rate)\n",
    "    \n",
    "    num_error_corrected = negative - wrong_negative\n",
    "    res.append(num_error_corrected)\n",
    "    \n",
    "    num_error_created = positive - right_positive\n",
    "    res.append(num_error_created)\n",
    "    \n",
    "    right_positive /= positive\n",
    "    res.append(right_positive)\n",
    "    \n",
    "    wrong_negative /= negative\n",
    "    res.append(wrong_negative)\n",
    "\n",
    "    return baseline, res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>The results</b>\n",
    "\n",
    "We use DataFrame here, so it costs much time.\n",
    "\n",
    "For test10, maybe 1 hours, For test20, maybe 3 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'wrong_negative_fb' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-59ff9d421b8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_part\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Here are the result of data-set with 10% error:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"------------------------------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The baseline is: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"------------------------------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-5c52fad03c90>\u001b[0m in \u001b[0;36mtest_part\u001b[0;34m(train, test)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_positive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mwrong_negative_fb\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrong_negative\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'wrong_negative_fb' referenced before assignment"
     ]
    }
   ],
   "source": [
    "baseline, fb = test_part(train10, test10)\n",
    "print(\"Here are the result of data-set with 10% error:\")\n",
    "print(\"------------------------------------------------------\")\n",
    "print(\"The baseline is: \" + str(baseline))\n",
    "print(\"------------------------------------------------------\")\n",
    "print(\"The error-rate using fb is: \" + str(fb[0]))\n",
    "print(\"The number of corrected error using fb is: \" + str(fb[1]))\n",
    "print(\"The number of created error using fb is: \" + str(fb[2]))\n",
    "print(\"The true positive rate using fb is: \" + str(fb[3]))\n",
    "print(\"The false negative rate using fb is: \" + str(fb[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the result of data-set with 20% error:\n",
      "------------------------------------------------------\n",
      "The baseline is: 0.19405667725121323\n",
      "------------------------------------------------------\n",
      "The error-rate using fb is: 0.30884908034269964\n",
      "The number of corrected error using fb is: 440.0\n",
      "The number of created error using fb is: 2356.0\n",
      "The true positive rate using fb is: 0.8248587570621468\n",
      "The false negative rate using fb is: [0.8641556035813522]\n",
      "------------------------------------------------------\n",
      "The error-rate using viterbi is: 0.133245461626026\n",
      "The number of corrected error using viterbi is: 1764.0\n",
      "The number of created error using viterbi is: 749.0\n",
      "The true positive rate using viterbi is: 0.9443205471305383\n",
      "The false negative rate using viterbi is: 0.45538746526705776\n"
     ]
    }
   ],
   "source": [
    "baseline, fb = test_part(train20, test20)\n",
    "print(\"Here are the result of data-set with 20% error:\")\n",
    "print(\"------------------------------------------------------\")\n",
    "print(\"The baseline is: \" + str(baseline))\n",
    "print(\"------------------------------------------------------\")\n",
    "print(\"The error-rate using fb is: \" + str(fb[0]))\n",
    "print(\"The number of corrected error using fb is: \" + str(fb[1]))\n",
    "print(\"The number of created error using fb is: \" + str(fb[2]))\n",
    "print(\"The true positive rate using fb is: \" + str(fb[3]))\n",
    "print(\"The false negative rate using fb is: \" + str(fb[4]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

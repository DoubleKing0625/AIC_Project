{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Coding by python2.7\n",
    "   \n",
    "authors: Qixiang PENG, Zizhao LI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import log_loss\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>lode data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "# class between [1,9]\n",
    "train_y = train['target'].apply(lambda s: int(s[-1:])).values\n",
    "train_X = train.drop('id', axis=1)\n",
    "train_X = train_X.drop('target', axis=1)\n",
    "X_test = pd.read_csv('./data/test.csv')\n",
    "X_test = X_test.drop('id', axis=1).values\n",
    "# split train set into 2 parts with same distribution: 80% train, 20% validation\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "for train_index, test_index in sss.split(train_X.values, train_y):\n",
    "    X_train = train_X.values[train_index]\n",
    "    X_val = train_X.values[test_index]\n",
    "\n",
    "    y_train = train_y[train_index]\n",
    "    y_val = train_y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>original xgboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The log loss is: 0.641349608103\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "pred = xgb.predict_proba(X_val)\n",
    "score = log_loss(y_val, pred)\n",
    "print \"The log loss is: \" + str(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> another xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The log loss is: 0.49081880946\n"
     ]
    }
   ],
   "source": [
    "xgb_original = XGBClassifier(max_depth=10, learning_rate=0.0825, subsample=0.85, colsample_bytree=0.8, \n",
    "                             min_child_weight=5.2475, objective='multi:softprob')\n",
    "xgb_original.fit(X_train, y_train)\n",
    "pred = xgb_original.predict_proba(X_val)\n",
    "score = log_loss(y_val, pred)\n",
    "print \"The log loss is: \" + str(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>fine-tune hyper-parameters of xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the default setting is\n",
    "\n",
    "# XGBClassifier(\n",
    "#  learning_rate =0.1,\n",
    "#  n_estimators=1000,\n",
    "#  max_depth=5,\n",
    "#  min_child_weight=1,\n",
    "#  gamma=0,\n",
    "#  subsample=0.8,\n",
    "#  colsample_bytree=0.8,\n",
    "#  nthread=4,\n",
    "#  scale_pos_weight=1,\n",
    "#  seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=4,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=27, silent=True, subsample=0.8),\n",
       "       fit_params=None, iid=False, n_jobs=4,\n",
       "       param_grid={'n_estimators': [100, 300, 500, 700, 900, 1100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_log_loss', verbose=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# firstly we set learning-rate as 0.1, and search the best n_estimator\n",
    "param_test1 = {\n",
    " 'n_estimators':range(100,1200,200)\n",
    " }\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.1, max_depth=5,\n",
    "min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8, nthread=4, scale_pos_weight=1, seed=27), \n",
    "param_grid = param_test1, scoring='neg_log_loss',n_jobs=4,iid=False, cv=3)\n",
    "gsearch1.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 700}\n",
      "-0.47375621873\n",
      "[mean: -0.56585, std: 0.00399, params: {'n_estimators': 100}, mean: -0.49265, std: 0.00492, params: {'n_estimators': 300}, mean: -0.47698, std: 0.00545, params: {'n_estimators': 500}, mean: -0.47376, std: 0.00546, params: {'n_estimators': 700}, mean: -0.47718, std: 0.00476, params: {'n_estimators': 900}, mean: -0.48339, std: 0.00481, params: {'n_estimators': 1100}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qixiangpeng/anaconda/envs/kaggle_seguro/lib/python2.7/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "print gsearch1.best_params_\n",
    "print gsearch1.best_score_\n",
    "print gsearch1.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=700, nthread=4,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=27, silent=True, subsample=0.8),\n",
       "       fit_params=None, iid=False, n_jobs=-1,\n",
       "       param_grid={'max_depth': [7, 9, 11, 13], 'min_child_weight': [1, 3, 5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_log_loss', verbose=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# then, fix learning-rate as 0.1, n_estimator = 700(if we have time, we can fine-tune it more precisely), fine-tune max_depth and min_weight\n",
    "param_test2 = {\n",
    " 'max_depth':range(7,14,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.1, n_estimators=700, gamma=0, subsample=0.8, colsample_bytree=0.8, nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test2, scoring='neg_log_loss',n_jobs=-1,iid=False, cv=3)\n",
    "gsearch2.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 7, 'min_child_weight': 5}\n",
      "[mean: -0.48923, std: 0.00547, params: {'max_depth': 7, 'min_child_weight': 1}, mean: -0.47768, std: 0.00529, params: {'max_depth': 7, 'min_child_weight': 3}, mean: -0.47311, std: 0.00620, params: {'max_depth': 7, 'min_child_weight': 5}, mean: -0.52020, std: 0.00630, params: {'max_depth': 9, 'min_child_weight': 1}, mean: -0.49668, std: 0.00543, params: {'max_depth': 9, 'min_child_weight': 3}, mean: -0.48558, std: 0.00643, params: {'max_depth': 9, 'min_child_weight': 5}, mean: -0.54164, std: 0.00535, params: {'max_depth': 11, 'min_child_weight': 1}, mean: -0.51054, std: 0.00599, params: {'max_depth': 11, 'min_child_weight': 3}, mean: -0.49757, std: 0.00608, params: {'max_depth': 11, 'min_child_weight': 5}, mean: -0.55157, std: 0.00511, params: {'max_depth': 13, 'min_child_weight': 1}, mean: -0.51923, std: 0.00503, params: {'max_depth': 13, 'min_child_weight': 3}, mean: -0.50647, std: 0.00610, params: {'max_depth': 13, 'min_child_weight': 5}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qixiangpeng/anaconda/envs/kaggle_seguro/lib/python2.7/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "print gsearch2.best_params_\n",
    "print gsearch2.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The log loss is: 0.444085652611\n"
     ]
    }
   ],
   "source": [
    "xgb_optimal = XGBClassifier(learning_rate =0.1, n_estimators=700, gamma=0, max_depth=7, min_child_weight=3, subsample=0.8, colsample_bytree=0.8, nthread=4, scale_pos_weight=1, seed=27, objective='multi:softprob')\n",
    "xgb_optimal.fit(X_train, y_train)\n",
    "pred = xgb_optimal.predict_proba(X_val)\n",
    "score = log_loss(y_val, pred)\n",
    "print \"The log loss is: \" + str(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = xgb_optimal.predict_proba(X_test)\n",
    "columns = [\"id\",\"Class_1\",\"Class_2\",\"Class_3\",\"Class_4\",\"Class_5\",\"Class_6\",\"Class_7\",\"Class_8\",\"Class_9\"]\n",
    "rlt = np.zeros(result.shape[0] * 9).reshape((result.shape[0],9)).astype(float)\n",
    "\n",
    "i = 0\n",
    "for class_i in result:\n",
    "    rlt[i] = class_i\n",
    "    i += 1\n",
    "    \n",
    "r = []\n",
    "i = 1\n",
    "for class_i in rlt:\n",
    "    p = [i] + list(map(str, class_i.tolist()))\n",
    "    i += 1\n",
    "    r.append(p)\n",
    "r = np.array(r)\n",
    "\n",
    "out = pd.DataFrame(r,columns = columns)\n",
    "out.to_csv('result_Xgboost.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

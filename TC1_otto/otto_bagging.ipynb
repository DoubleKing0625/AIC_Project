{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Coding by python2.7\n",
    "   \n",
    "authors: Qixiang PENG, Zizhao LI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qixiangpeng/anaconda/envs/kaggle_seguro/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "# class between [1,9]\n",
    "train_y = train['target'].apply(lambda s: int(s[-1:])).values\n",
    "train_X = train.drop('id', axis=1)\n",
    "train_X = train_X.drop('target', axis=1)\n",
    "X_test = pd.read_csv('./data/test.csv')\n",
    "X_test = X_test.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>use random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train set into 2 parts with same distribution: 80% train, 20% validation\n",
    "sss1 = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "for train_index, test_index in sss1.split(train_X.values, train_y):\n",
    "    X_train = train_X.values[train_index]\n",
    "    X_val = train_X.values[test_index]\n",
    "\n",
    "    y_train = train_y[train_index]\n",
    "    y_val = train_y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The log loss of random forest is: 0.485162164708\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=900, max_depth=50, max_features=0.3, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "carf = CalibratedClassifierCV(rf, method=\"isotonic\", cv=5)\n",
    "carf.fit(X_train, y_train)\n",
    "pred1 = carf.predict_proba(X_val)\n",
    "score = log_loss(y_val, pred1)\n",
    "print \"The log loss of random forest is: \" + str(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>use xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train set into 2 parts with same distribution: 80% train, 20% validation\n",
    "sss2 = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "for train_index, test_index in sss2.split(train_X.values, train_y):\n",
    "    X_train = train_X.values[train_index]\n",
    "    X_val = train_X.values[test_index]\n",
    "\n",
    "    y_train = train_y[train_index]\n",
    "    y_val = train_y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The log loss of xgb is: 0.49081880946\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(max_depth=10, learning_rate=0.0825, subsample=0.85, colsample_bytree=0.8, \n",
    "                             min_child_weight=5.2475, objective='multi:softprob')\n",
    "xgb.fit(X_train, y_train)\n",
    "pred2 = xgb.predict_proba(X_val)\n",
    "score = log_loss(y_val, pred2)\n",
    "print \"The log loss of xgb is: \" + str(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>use extra-tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train set into 2 parts with same distribution: 80% train, 20% validation\n",
    "sss3 = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "for train_index, test_index in sss3.split(train_X.values, train_y):\n",
    "    X_train = train_X.values[train_index]\n",
    "    X_val = train_X.values[test_index]\n",
    "\n",
    "    y_train = train_y[train_index]\n",
    "    y_val = train_y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The log loss extra-tree is: 0.471821131449\n"
     ]
    }
   ],
   "source": [
    "et = ExtraTreesClassifier(n_estimators=1000, max_depth=80, max_features=0.7, n_jobs=-1)\n",
    "et.fit(X_train, y_train)\n",
    "caet = CalibratedClassifierCV(et, method=\"isotonic\", cv=5)\n",
    "caet.fit(X_train, y_train)\n",
    "pred3 = caet.predict_proba(X_val)\n",
    "score = log_loss(y_val, pred3)\n",
    "print \"The log loss extra-tree is: \" + str(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The log loss bagging is: 0.473403001831\n"
     ]
    }
   ],
   "source": [
    "pred = (pred1 + pred1 + pred2) * 1.0 / 3\n",
    "score = log_loss(y_val, pred)\n",
    "print \"The log loss bagging is: \" + str(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> expot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = carf.predict_proba(X_test)\n",
    "result2 = xgb.predict_proba(X_test.values)\n",
    "result3 = caet.predict_proba(X_test)\n",
    "result = (result1 + result2 + result3) * 1.0 / 3 \n",
    "columns = [\"id\",\"Class_1\",\"Class_2\",\"Class_3\",\"Class_4\",\"Class_5\",\"Class_6\",\"Class_7\",\"Class_8\",\"Class_9\"]\n",
    "rlt = np.zeros(result.shape[0] * 9).reshape((result.shape[0],9)).astype(float)\n",
    "\n",
    "i = 0\n",
    "for class_i in result:\n",
    "    rlt[i] = class_i\n",
    "    i += 1\n",
    "    \n",
    "r = []\n",
    "i = 1\n",
    "for class_i in rlt:\n",
    "    p = [i] + list(map(str, class_i.tolist()))\n",
    "    i += 1\n",
    "    r.append(p)\n",
    "r = np.array(r)\n",
    "\n",
    "out = pd.DataFrame(r,columns = columns)\n",
    "out.to_csv('result_Bagging.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
